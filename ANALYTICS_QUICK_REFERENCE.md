# Analytics Layer - Quick Reference Guide

**For:** Developers, DevOps, Product Teams
**Version:** 1.0.0

---

## ðŸš€ Quick Start

### Local Development
```bash
# Terminal 1: Backend
cd server && npm install && npm run dev

# Terminal 2: Monitor cron jobs (once server starts)
tail -f logs/server.log | grep "cron\|aggregation"
```

### Production Deployment
```bash
# Deploy backend
cd server && npm run build && npm start

# Server will automatically:
# âœ“ Initialize cron jobs
# âœ“ Connect to MongoDB
# âœ“ Start analytics scheduler
```

---

## ðŸ”‘ Key Files & Their Purpose

| File | Purpose | Lines |
|------|---------|-------|
| `server/src/models/Analytics.ts` | 6 MongoDB schemas | 335 |
| `server/src/services/analytics.service.ts` | Event logging & metric calc | 450 |
| `server/src/services/aggregation.service.ts` | Daily batch jobs | 325 |
| `server/src/routes/analytics-api.routes.ts` | 11 API endpoints | 400 |
| `server/src/utils/privacy.ts` | Anonymization & GDPR | 280 |
| `server/src/utils/export.ts` | CSV/JSON export | 390 |
| `server/src/jobs/scheduler.ts` | Cron job orchestration | 200 |
| `server/src/index.ts` | **Modified** - Init scheduler | +6 lines |

---

## ðŸ“Š Database Collections

| Collection | Purpose | Size | TTL |
|------------|---------|------|-----|
| `usermetrics` | User aggregates | Small | None |
| `performancelogs` | Q&A data (time-series) | Large | 1 year |
| `subtopicmetrics` | Learning progress | Medium | None |
| `engagementevents` | Behavioral tracking | Large | 6 months |
| `dailycohortmetrics` | Daily aggregates | Tiny | None |
| `sentimentlogs` | Survey data | Small | None |

---

## ðŸ”„ Event Flow

```
User Action
    â†“
Frontend logs via AnalyticsService
    â†“
Real-time Update
    â”œâ”€ PerformanceLog (immediate)
    â”œâ”€ EngagementEvent (immediate)
    â””â”€ UserMetrics (async, queued)
    â†“
Daily Aggregation (00:00 UTC)
    â”œâ”€ calculateDailyCohortMetrics()
    â”œâ”€ batchUpdateAllUserMetrics()
    â””â”€ calculateRetentionCohorts()
    â†“
Investor Dashboard (live query)
    â”œâ”€ /api/analytics/dashboard/overview
    â”œâ”€ /api/analytics/dashboard/learning-efficacy
    â””â”€ /api/analytics/dashboard/gacha-economics
```

---

## ðŸ“¡ API Endpoints Cheat Sheet

### User Analytics (Requires Auth)
```bash
# Learning progress
curl -H "Authorization: Bearer TOKEN" \
  http://localhost:5000/api/analytics/user/learning

# Engagement metrics
curl -H "Authorization: Bearer TOKEN" \
  http://localhost:5000/api/analytics/user/engagement

# Gacha economics
curl -H "Authorization: Bearer TOKEN" \
  http://localhost:5000/api/analytics/user/gacha

# Recent performance
curl -H "Authorization: Bearer TOKEN" \
  "http://localhost:5000/api/analytics/user/performance?limit=50"
```

### Investor Dashboard (Public)
```bash
# Overview metrics
curl http://localhost:5000/api/analytics/dashboard/overview

# Retention rates
curl http://localhost:5000/api/analytics/dashboard/retention

# Learning efficacy (75% above average)
curl http://localhost:5000/api/analytics/dashboard/learning-efficacy

# Gacha success (evolution adoption)
curl http://localhost:5000/api/analytics/dashboard/gacha-economics

# Email nudge performance
curl http://localhost:5000/api/analytics/dashboard/nudge-efficacy
```

### Export Data
```bash
# JSON format (for programmatic use)
curl "http://localhost:5000/api/analytics/export/dashboard-metrics?format=json" \
  > metrics.json

# CSV format (for Excel/Sheets)
curl "http://localhost:5000/api/analytics/export/dashboard-metrics?format=csv" \
  > metrics.csv
```

---

## ðŸŽ¯ Common Tasks

### Log a Question Answer
```typescript
import { AnalyticsService } from '@/services/analytics.service';

await AnalyticsService.logPerformance({
  userId: user.id,
  subtopicId: 'reading-comp-1',
  questionId: 'q-12345',
  isCorrect: true,
  difficultyLevel: 'Medium',
  timeSpentSeconds: 45
});
```

### Log a Mission Completion
```typescript
await AnalyticsService.logEngagementEvent({
  userId: user.id,
  eventType: 'mission_complete',
  eventData: {
    missionId: 'mission-2026-01-19',
    questionCount: 20,
    correctCount: 18,
    sessionDuration: 15
  }
});
```

### Log an Email Conversion
```typescript
await AnalyticsService.logNudgeConversion({
  userId: user.id,
  nudgeType: 'morning',  // 8 AM
  conversionTimeMinutes: 45
});
```

### Get User's Learning Progress
```typescript
const progress = await AnalyticsService.getUserLearningProgress(userId);
// Returns: accuracy, questions, streaks, percentile milestones
```

### Run Aggregation Manually
```bash
node -e "require('./src/jobs/scheduler').runDailyAggregationNow()"
```

### Generate Investor Report
```bash
node -e "require('./src/jobs/scheduler').generateInvestorReportNow()"
```

---

## ðŸ”’ Privacy Checklist

**Before exporting data:**
```typescript
import { validateAnonymization, anonymizeUserMetrics } from '@/utils/privacy';

// Anonymize user data
const anonUser = anonymizeUserMetrics(userMetrics);

// Validate it's safe to export
const {isAnonymized, issues} = validateAnonymization(anonUser);
if (!isAnonymized) {
  console.error('Not anonymized:', issues);
  return;
}

// Safe to send to investors
sendToInvestors(anonUser);
```

**For GDPR deletion:**
```typescript
import { prepareUserForDeletion } from '@/utils/privacy';

const result = await prepareUserForDeletion(userId);
// Archives user data for 90 days, then auto-deletes
```

---

## âš™ï¸ Cron Job Configuration

All jobs are auto-configured and run automatically:

| Job | Runs | Purpose |
|-----|------|---------|
| Daily Aggregation | Every day at 00:00 UTC | Calculate DAU/MAU |
| Hourly Nudge Metrics | Every hour at :00 | Email conversion rates |
| Weekly Retention | Sunday at 02:00 UTC | Cohort analysis |
| Monthly Report | 1st at 03:00 UTC | Investor metrics |

**To disable a job:** Edit `server/src/jobs/scheduler.ts` and comment out the schedule

---

## ðŸ“ˆ Metrics to Understand

### User Metrics
- **accuracy**: % correct answers (0-100)
- **currentStreak**: Days completed in a row
- **longestStreak**: Best ever streak
- **nudgeConversionRate**: % of emails â†’ mission completion

### Cohort Metrics
- **DAU**: Distinct users active today
- **Churn**: Users inactive 7+ days
- **Retention**: DAU today / DAU 7 days ago

### Learning Metrics
- **Percentile25**: % of users above average on â‰¥25 subtopics
- **accuracyDelta**: Improvement from baseline to current
- **calibrationVelocity**: Questions needed to advance difficulty

### Gacha Metrics
- **evolutionPenetration**: % of users with â‰¥1 evolution
- **summonsPerUser**: Average summons per user
- **auraBalance**: Total aura in player economy

---

## ðŸ” Debugging Commands

### Check MongoDB Connection
```bash
mongosh "mongodb+srv://..." --eval "db.adminCommand('ping')"
```

### Verify All Indexes Are Created
```bash
mongosh
> use auraprep
> db.usermetrics.getIndexes()
> db.performancelogs.getIndexes()
```

### Check Cron Job Logs
```bash
# See all cron job executions
grep "cron\|aggregation\|job" server.log

# Real-time monitoring
tail -f server.log | grep "aggregation"
```

### Count Documents in Each Collection
```bash
mongosh
> db.usermetrics.countDocuments()
> db.performancelogs.countDocuments()
> db.engagementevents.countDocuments()
```

### Test API Response Time
```bash
time curl http://localhost:5000/api/analytics/dashboard/overview
```

---

## ðŸš¨ Common Issues & Fixes

### "Cron jobs not initializing"
```
Check: Is AnalyticsScheduler.initializeJobs() called in server/src/index.ts?
Expected log: "âœ… All analytics cron jobs initialized"
```

### "Empty metrics in dashboard"
```
Check:
1. Are events being logged? db.engagementevents.count()
2. Has 00:00 UTC passed? Check server.log for aggregation
3. Query directly: db.usermetrics.findOne()
```

### "MongoDB TTL index not deleting old data"
```
Create: db.performancelogs.createIndex(
  {timestamp: 1},
  {expireAfterSeconds: 31536000}
)
MongoDB runs cleanup every 60 seconds
```

### "High query latency on analytics endpoints"
```
Check:
1. Indexes exist: db.collection.getIndexes()
2. Query plan: db.collection.find(...).explain("executionStats")
3. Consider caching frequently accessed queries
```

---

## ðŸŽ“ Understanding the Data Model

### Questions â†’ Performance â†’ Learning
```
User answers 100 questions on "reading-comp"
â†“
Each answer logged to PerformanceLog
â†“
AnalyticsService calculates baseline (first 10) vs current (last 50)
â†“
If accuracy improves 15%+, mark as "moved above percentile"
â†“
Dashboard shows: "User mastered this subtopic"
```

### Events â†’ Engagement â†’ Retention
```
User logs in â†’ EngagementEvent: "login"
â†“
User completes mission â†’ EngagementEvent: "mission_complete"
â†“
Streak incremented (if consecutive days)
â†“
Daily Aggregation counts DAU, calculates retention
â†“
If no activity for 7+ days â†’ marked as "churn"
```

### Nudges â†’ Conversions â†’ ROI
```
Email sent at 8 AM â†’ tracked with timestamp
â†“
User clicks link, auto-logged in via JWT token
â†“
Within 2 hours, user completes mission
â†“
Logged as nudge_conversion with type="morning"
â†“
Email system gets credit for +1 conversion
```

---

## ðŸ“š Documentation Files

| File | Purpose | Read Time |
|------|---------|-----------|
| `ANALYTICS_IMPLEMENTATION.md` | Complete technical reference | 30 min |
| `ANALYTICS_QUICK_REFERENCE.md` | This file! Quick lookup | 5 min |
| `server/src/models/Analytics.ts` | TypeScript schema definitions | 10 min |
| `server/src/services/analytics.service.ts` | Business logic examples | 15 min |

---

## ðŸŽ¯ Next Steps (After Deployment)

### Week 1: Verify System
- [ ] Check first daily aggregation (00:00 UTC)
- [ ] Verify all cron jobs executed
- [ ] Test export endpoints
- [ ] Confirm metrics in dashboard

### Week 2: Monitor Performance
- [ ] Track query latency (P95, P99)
- [ ] Monitor MongoDB disk usage
- [ ] Check error rates in logs
- [ ] Validate data accuracy

### Week 3: Integration
- [ ] Integrate AnalyticsService into App.tsx
- [ ] Start logging question answers
- [ ] Start logging mission completions
- [ ] Verify events flow to MongoDB

### Week 4: Optimization
- [ ] Analyze slow queries
- [ ] Add caching if needed
- [ ] Consider archiving old PerformanceLogs
- [ ] Prepare for investor demo

---

## ðŸ’¡ Pro Tips

1. **Always batch operations** - Use batchSize of 100 to avoid memory issues
2. **Use TTL indexes** - PerformanceLog automatically cleaned up after 1 year
3. **Check logs first** - Most issues visible in server logs
4. **Test locally** - Run aggregation manually: `runDailyAggregationNow()`
5. **Monitor MongoDB** - Watch active connections and query times
6. **Anonymize before sharing** - Always use `validateAnonymization()`
7. **Archive exports** - Keep monthly exports for audit trail
8. **Test aggregations** - Run early in deployment to catch data quality issues

---

## ðŸ“ž When to Escalate

| Issue | Escalate To | Action |
|-------|-------------|--------|
| MongoDB connection fails | DevOps/DBA | Check connection string, network |
| TTL cleanup not working | MongoDB Support | Verify TTL index configuration |
| Query too slow | Database team | Profile query with `.explain()` |
| Privacy validation fails | Compliance team | Review anonymization logic |
| Cron jobs not running | Backend team | Check scheduler initialization |

---

**Last Updated:** January 2026
**Status:** âœ… COMPLETE & PRODUCTION READY
